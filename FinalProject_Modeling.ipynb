{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB         # Naive Bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>transit</th>\n",
       "      <th>access</th>\n",
       "      <th>house_rules</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>price</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <th>first_review</th>\n",
       "      <th>last_review</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>price_int</th>\n",
       "      <th>price_bed</th>\n",
       "      <th>Host_Age</th>\n",
       "      <th>RPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>3583</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Great Location; Train and Restaurants</td>\n",
       "      <td>My place is close to Taco Loco Mexican Grill, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My place is close to Taco Loco Mexican Grill, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>Hi, I am very friendly, helpful, positive and ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Somerville</td>\n",
       "      <td>02145</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{Kitchen,Gym,\"Family/Kid Friendly\",Washer,Drye...</td>\n",
       "      <td>$65.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>2016-08-27</td>\n",
       "      <td>2016-09-04</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 last_scraped                                   name  \\\n",
       "2828        3583   2016-09-07  Great Location; Train and Restaurants   \n",
       "\n",
       "                                                summary space  \\\n",
       "2828  My place is close to Taco Loco Mexican Grill, ...   NaN   \n",
       "\n",
       "                                            description neighborhood_overview  \\\n",
       "2828  My place is close to Taco Loco Mexican Grill, ...                   NaN   \n",
       "\n",
       "     transit access house_rules  host_since  \\\n",
       "2828     NaN    NaN         NaN  2016-05-27   \n",
       "\n",
       "                                             host_about  \\\n",
       "2828  Hi, I am very friendly, helpful, positive and ...   \n",
       "\n",
       "      host_total_listings_count neighbourhood zipcode     room_type  \\\n",
       "2828                          4    Somerville   02145  Private room   \n",
       "\n",
       "      accommodates  bathrooms  beds  bed_type  \\\n",
       "2828             2        1.0   1.0  Real Bed   \n",
       "\n",
       "                                              amenities   price  \\\n",
       "2828  {Kitchen,Gym,\"Family/Kid Friendly\",Washer,Drye...  $65.00   \n",
       "\n",
       "      availability_90 calendar_last_scraped first_review last_review  \\\n",
       "2828                5            2016-09-06   2016-08-27  2016-09-04   \n",
       "\n",
       "      calculated_host_listings_count  reviews_per_month  price_int  price_bed  \\\n",
       "2828                               1                2.0       65.0       65.0   \n",
       "\n",
       "      Host_Age  RPM  \n",
       "2828       103    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = r'../FinalProjectEDA/AB_Clean.csv'\n",
    "pd.set_option('display.max_columns', 500)\n",
    "AB_Clean = pd.read_csv(data)\n",
    "AB_Clean.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression with quantitative variables\n",
    "\n",
    "The list of my quantitative variables is below\n",
    "\n",
    "- host_total_listings_count\n",
    "- accomodates\n",
    "- availability 90\n",
    "- price_bed\n",
    "- Host_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantatiate a logistic regression and fit model with all the quant vars. \n",
    "# Fit a logistic regression model and store the class predictions.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "feature_cols = ['host_total_listings_count','accommodates','availability_90','price_bed','Host_Age']\n",
    "X = AB_Clean[feature_cols]\n",
    "y = AB_Clean.RPM\n",
    "\n",
    "logreg.fit(X,y)\n",
    "pred = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.607281724991163"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of model\n",
    "logreg.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00478119,  0.05927462,  0.0054951 , -0.00240966, -0.00037408])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show coefficients, accommodates is the most influential\n",
    "coef = logreg.coef_[0]\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat logistic regression with train, test, split \n",
    "# using train test split to cross val\n",
    "logreg2 = LogisticRegression()\n",
    "\n",
    "feature_cols = ['host_total_listings_count','accommodates','availability_90','price_bed','Host_Age']\n",
    "X = AB_Clean[feature_cols]\n",
    "y = AB_Clean.RPM\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state =42)\n",
    "\n",
    "\n",
    "logreg2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log reg score increases by ~4% when incorporating train, test, split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.6483050847457628\n",
      "Precision Score : 0.6402321083172147\n",
      "Recall Score : 0.8401015228426396\n",
      "F1 Score : 0.7266739846322723\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef2 = logreg2.coef_[0]\n",
    "coef2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since accommodates is the highest rated variable I will do one additional logreg using this as the predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat logistic regression with train, test, split \n",
    "# using train test split to cross val\n",
    "logreg3 = LogisticRegression()\n",
    "\n",
    "feature_cols = ['host_total_listings_count','availability_90','price_bed','Host_Age']\n",
    "X = AB_Clean[feature_cols]\n",
    "y = AB_Clean.RPM\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state =42)\n",
    "\n",
    "\n",
    "logreg3.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying several comibinations of variables droppping \"accommodates\" from the list of columns resulted in the highest scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef3 = logreg3.coef_[0]\n",
    "coef3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP with text columns\n",
    "\n",
    "The list of my text variables is below\n",
    "\n",
    "- Name\n",
    "- host_about\n",
    "- description\n",
    "\n",
    "I will test my variables using count vectorizer and DF/IDF, to find the best. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_Clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new table with just the text columns and RPM\n",
    "\n",
    "AB_Clean_text = AB_Clean[['host_about','name','description','RPM']]\n",
    "AB_Clean_text['host_about']=AB_Clean_text['host_about'].astype(str)\n",
    "AB_Clean_text.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP with name field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using name and adjusting a couple of parameters I get a score of ~63.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y.\n",
    "X = AB_Clean_text.name\n",
    "y = AB_Clean_text.RPM\n",
    "\n",
    "# Split the new DataFrame into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# use default options for CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english',ngram_range=(2,4),max_features=10000)\n",
    "\n",
    "# create document-term matrices\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# use Naive Bayes  to predict the star rating\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When description is the text field the score goes up to ~68.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y.\n",
    "X = AB_Clean_text.description\n",
    "y = AB_Clean_text.RPM\n",
    "\n",
    "# Split the new DataFrame into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "\n",
    "# use default options for CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english',ngram_range=(1,2),max_features=10000)\n",
    "\n",
    "# create document-term matrices\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# use Naive Bayes  to predict the star rating\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the host about column we get the lowest score of ~61.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y.\n",
    "X = AB_Clean_text.host_about\n",
    "y = AB_Clean_text.RPM\n",
    "\n",
    "# Split the new DataFrame into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "\n",
    "# use default options for CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english',ngram_range=(1,2),max_features=10000)\n",
    "\n",
    "# create document-term matrices\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# use Naive Bayes  to predict the star rating\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the description column and a TF/IDF vectorizer, as well as setting the max_df to 1000 I am able to increase the accuracy to ~68.9%!\n",
    "\n",
    "#### This is 13% above the training value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y.\n",
    "X = AB_Clean_text.description\n",
    "y = AB_Clean_text.RPM\n",
    "\n",
    "# Split the new DataFrame into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# use default options for CountVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english',ngram_range=(1,2),max_df=1000,max_features=10000)\n",
    "\n",
    "# create document-term matrices\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# use Naive Bayes  to predict the star rating\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine text and quantitative variables using Naive Bayes, as well as Logistic Regression to see which performs best out of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_total_listings_count      int64\n",
       "availability_90                int64\n",
       "price_bed                    float64\n",
       "Host_Age                       int64\n",
       "description                   object\n",
       "RPM                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table with just desired variables\n",
    "# I used description as the text field because this was the best predictor from the text columns\n",
    "# Apply Train Test Split\n",
    "AB_Clean_Vars = AB_Clean[['host_total_listings_count','availability_90','price_bed','Host_Age','description','RPM']]\n",
    "AB_Clean_Vars.head(3)\n",
    "\n",
    "feature_cols = ['host_total_listings_count','availability_90','price_bed','Host_Age','description']\n",
    "X = AB_Clean_Vars[feature_cols]\n",
    "y= AB_Clean_Vars.RPM\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)\n",
    "AB_Clean_Vars.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2121, 10000)\n",
      "(708, 10000)\n"
     ]
    }
   ],
   "source": [
    "# I am going to use TfIdf to create the matrix and leave the same parameters that I used for the best predictive model\n",
    "vect = TfidfVectorizer(stop_words='english',ngram_range=(1,2),max_df=1000,max_features=10000)\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train.description)\n",
    "X_test_dtm = vect.transform(X_test.description)\n",
    "print((X_train_dtm.shape))\n",
    "print((X_test_dtm.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(708, 10004)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast other feature columns to float and convert to a sparse matrix.\n",
    "extra = sp.sparse.csr_matrix(X_train.drop('description', axis=1).astype(float))\n",
    "extra.shape\n",
    "\n",
    "# Combine sparse matrices for training and testing datasets respectively\n",
    "X_train_dtm_extra = sp.sparse.hstack((X_train_dtm, extra))\n",
    "X_train_dtm_extra.shape\n",
    "\n",
    "\n",
    "extra = sp.sparse.csr_matrix(X_test.drop('description', axis=1).astype(float))\n",
    "X_test_dtm_extra = sp.sparse.hstack((X_test_dtm, extra))\n",
    "X_test_dtm_extra.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 71% accuracy using logistic regression with all quantitaive test variables and the description.This ended up being the best model for this set of data. The value of 71% was ~16% more accurate than the null hypothesis. This model also has the highest precision score of all the models meaning that it has a good balance of bias vs. variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.71045197740113\n",
      "Precision Score : 0.7266187050359713\n",
      "Recall Score : 0.7690355329949239\n",
      "F1 Score : 0.7472256473489519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3_v2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Use logistic regression with all features, and print out LogReg metrics\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train_dtm_extra, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "#print((metrics.accuracy_score(y_test, y_pred_class)))\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_class)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_class)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_class)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_class)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.635593220338983\n",
      "Precision Score : 0.6069182389937107\n",
      "Recall Score : 0.9796954314720813\n",
      "F1 Score : 0.7495145631067961\n"
     ]
    }
   ],
   "source": [
    "# Use Naive Bayes with all features, and print out LogReg metrics\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm_extra, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm_extra)\n",
    "#print((metrics.accuracy_score(y_test, y_pred_class)))\n",
    "\n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_class)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred_class)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred_class)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
